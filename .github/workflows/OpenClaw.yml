name: OpenClaw Automated Onboarding

on:
  workflow_dispatch:
    inputs:
      llm_provider:
        description: 'LLM provider to use'
        required: true
        type: choice
        options:
          - 'qwen (Qwen3 Coder Plus via encrypted tokens)'
          - 'gemini (Gemini 2.5 Pro via encrypted Gemini CLI tokens)'
        default: 'qwen (Qwen3 Coder Plus via encrypted tokens)'
      encrypted_tokens:
        description: 'Encrypted tokens (base64-encoded AES-256-CBC) — Qwen tokens OR Gemini CLI tokens depending on provider choice'
        required: true
        type: string
      decryption_password:
        description: 'Password to decrypt the tokens'
        required: true
        type: string
      discord_bot_token:
        description: 'Discord bot token for channel configuration'
        required: true
        type: string

jobs:
  onboard-and-run:
    runs-on: ubuntu-latest
    timeout-minutes: 360

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      # ──────────────────────────────────────────────
      # 0. Mask sensitive inputs so they don't leak in logs
      # ──────────────────────────────────────────────

      - name: Mask secrets
        run: |
          echo "::add-mask::${{ github.event.inputs.encrypted_tokens }}"
          echo "::add-mask::${{ github.event.inputs.decryption_password }}"
          echo "::add-mask::${{ github.event.inputs.discord_bot_token }}"

      # ──────────────────────────────────────────────
      # 0.5. Determine provider and model from dropdown
      # ──────────────────────────────────────────────

      - name: Determine LLM provider and model
        run: |
          set -euo pipefail
          PROVIDER_CHOICE="${{ github.event.inputs.llm_provider }}"
          echo "Provider choice: $PROVIDER_CHOICE"

          if [[ "$PROVIDER_CHOICE" == *"gemini"* ]]; then
            echo "PROVIDER=gemini" >> "$GITHUB_ENV"
            echo "MODEL_ID=gemini-2.5-pro" >> "$GITHUB_ENV"
            echo "CONTEXT_WINDOW=1048576" >> "$GITHUB_ENV"
            echo "MAX_TOKENS=65536" >> "$GITHUB_ENV"
            echo "TOKEN_PATTERN=gemini-cli-*.json" >> "$GITHUB_ENV"
            echo "Selected: Gemini 2.5 Pro (context: 1048576, maxTokens: 65536)"
          else
            echo "PROVIDER=qwen" >> "$GITHUB_ENV"
            echo "MODEL_ID=qwen3-coder-plus" >> "$GITHUB_ENV"
            echo "CONTEXT_WINDOW=131072" >> "$GITHUB_ENV"
            echo "MAX_TOKENS=32768" >> "$GITHUB_ENV"
            echo "TOKEN_PATTERN=qwen-*.json" >> "$GITHUB_ENV"
            echo "Selected: Qwen3 Coder Plus (context: 131072, maxTokens: 32768)"
          fi

      # ──────────────────────────────────────────────
      # 1. Setup runtimes
      # ──────────────────────────────────────────────

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.22'
          cache: false

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      # ──────────────────────────────────────────────
      # 2. Install OpenClaw
      # ──────────────────────────────────────────────

      - name: Install OpenClaw
        run: |
          set -euo pipefail
          echo "::group::Installing OpenClaw"
          npm install -g openclaw@latest
          echo "OpenClaw version: $(openclaw --version)"
          echo "::endgroup::"

      - name: Fix OpenClaw extension permissions
        run: |
          set -euo pipefail
          echo "::group::Fixing extension permissions"

          # npm global installs on GitHub Actions have 777 permissions on the
          # extensions directory. OpenClaw's gateway blocks "world-writable"
          # plugin paths for security reasons. Fix by removing the world-writable bit.
          OPENCLAW_DIR=$(npm root -g)/openclaw
          if [ -d "$OPENCLAW_DIR/extensions" ]; then
            echo "Fixing permissions on $OPENCLAW_DIR/extensions"
            chmod -R o-w "$OPENCLAW_DIR/extensions"
            echo "Permissions fixed. Sample:"
            ls -la "$OPENCLAW_DIR/extensions/" | head -10
          else
            echo "::warning::OpenClaw extensions directory not found at $OPENCLAW_DIR/extensions"
          fi

          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 3. Build & install CLIProxyAPI from source
      # ──────────────────────────────────────────────

      - name: Install CLIProxyAPI from source
        run: |
          set -euo pipefail
          echo "::group::Building CLIProxyAPI"
          git clone --depth 1 https://github.com/router-for-me/CLIProxyAPI.git /tmp/CLIProxyAPI
          cd /tmp/CLIProxyAPI
          go build -o cli-proxy-api ./cmd/server
          sudo mv cli-proxy-api /usr/local/bin/cliproxyapi
          cd /
          rm -rf /tmp/CLIProxyAPI
          echo "CLIProxyAPI installed:"
          cliproxyapi --help || true
          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 4. Decrypt tokens and set up CLIProxyAPI
      # ──────────────────────────────────────────────

      - name: Decrypt tokens
        env:
          ENCRYPTED_TOKENS: ${{ github.event.inputs.encrypted_tokens }}
          DECRYPTION_PASSWORD: ${{ github.event.inputs.decryption_password }}
        run: |
          set -euo pipefail
          echo "::group::Decrypting $PROVIDER tokens"

          AUTH_DIR="$HOME/.cli-proxy-api"
          mkdir -p "$AUTH_DIR"
          chmod 700 "$AUTH_DIR"

          TEMP_DIR=$(mktemp -d)
          cd "$TEMP_DIR"

          # Decode base64
          echo "$ENCRYPTED_TOKENS" | base64 -d > tokens.enc

          # Decrypt with AES-256-CBC
          openssl enc -aes-256-cbc -d -salt -pbkdf2 \
            -in tokens.enc \
            -out tokens.tar.gz \
            -pass pass:"$DECRYPTION_PASSWORD"

          # Extract token files into auth directory
          tar -xzf tokens.tar.gz -C "$AUTH_DIR"

          # Count token files based on provider
          TOKEN_COUNT=$(find "$AUTH_DIR" -maxdepth 1 -name "$TOKEN_PATTERN" 2>/dev/null | wc -l)
          echo "Decrypted $TOKEN_COUNT $PROVIDER token file(s)"

          if [ "$TOKEN_COUNT" -eq 0 ]; then
            echo "::error::No $PROVIDER token files found after decryption!"
            echo "Expected pattern: $TOKEN_PATTERN"
            echo "Files found in auth dir:"
            ls -la "$AUTH_DIR/" || true
            echo ""
            echo "Verify the encrypted_tokens input and decryption_password are correct."
            echo "For Qwen: token files should be named qwen-*.json"
            echo "For Gemini: token files should be named gemini-cli-*.json"
            rm -rf "$TEMP_DIR"
            exit 1
          fi

          echo "Token files found: $TOKEN_COUNT"

          # Cleanup temp files
          rm -rf "$TEMP_DIR"

          echo "AUTH_DIR=$AUTH_DIR" >> "$GITHUB_ENV"
          echo "::endgroup::"

      - name: Create CLIProxyAPI config
        run: |
          set -euo pipefail
          echo "::group::Creating CLIProxyAPI config"

          cat > "$AUTH_DIR/config.yaml" <<EOF
          port: 8317
          host: "127.0.0.1"
          auth-dir: "$AUTH_DIR"
          debug: true
          logging-to-file: false
          api-keys:
            - "dummykey"
          routing:
            strategy: "round-robin"
          request-retry: 1
          EOF

          echo "CLIProxyAPI config created"
          cat "$AUTH_DIR/config.yaml"
          echo "::endgroup::"

      - name: Start CLIProxyAPI
        run: |
          set -euo pipefail
          echo "::group::Starting CLIProxyAPI"

          # Start CLIProxyAPI in background with logs going to a file AND stdout
          nohup cliproxyapi -config "$AUTH_DIR/config.yaml" > /tmp/cliproxyapi.log 2>&1 &
          PROXY_PID=$!
          echo "CLIProxyAPI started (PID: $PROXY_PID)"
          echo "PROXY_PID=$PROXY_PID" >> "$GITHUB_ENV"

          # Wait for the proxy to be ready (use auth header since api-keys are configured)
          echo "Waiting for CLIProxyAPI to be ready..."
          READY=false
          for i in $(seq 1 60); do
            # Check if process is still alive
            if ! kill -0 $PROXY_PID 2>/dev/null; then
              echo "::error::CLIProxyAPI process died unexpectedly"
              cat /tmp/cliproxyapi.log || true
              exit 1
            fi

            # Try health check with auth header
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
              -H "Authorization: Bearer dummykey" \
              http://127.0.0.1:8317/v1/models 2>/dev/null | head -c3 || echo "000")

            if [ "$HTTP_CODE" = "200" ]; then
              echo "CLIProxyAPI is ready! (HTTP $HTTP_CODE)"
              READY=true
              break
            fi

            echo "  Attempt $i/60: HTTP $HTTP_CODE - waiting..."
            sleep 2
          done

          if [ "$READY" = "false" ]; then
            echo "::warning::CLIProxyAPI didn't return 200 within 120 seconds"
            echo "Last CLIProxyAPI logs:"
            tail -30 /tmp/cliproxyapi.log || true
            echo ""
            echo "Continuing anyway (onboarding uses --custom-compatibility openai to skip probing)"
          fi

          # Show available models
          echo ""
          echo "Available models:"
          curl -s -H "Authorization: Bearer dummykey" \
            http://127.0.0.1:8317/v1/models 2>/dev/null | jq '.data[].id' 2>/dev/null || echo "(could not list models)"

          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 4.5. Start rate-limit-aware proxy (sits between
      #      OpenClaw on port 8318 and CLIProxyAPI on 8317)
      #
      #      FIXES: Qwen 60 req/min rate limit causing
      #      permanent "API rate limit reached" errors.
      #      The proxy transparently queues, waits, and
      #      retries so OpenClaw never sees a 429.
      # ──────────────────────────────────────────────

      - name: Create rate-limit proxy
        run: |
          set -euo pipefail
          echo "::group::Creating rate-limit proxy"

          cat > /tmp/rate-limit-proxy.mjs << 'PROXY_EOF'
          import http from "node:http";

          // ── Configuration ─────────────────────────────
          const LISTEN_PORT = 8318;
          const UPSTREAM_HOST = "127.0.0.1";
          const UPSTREAM_PORT = 8317;
          const RPM_LIMIT = 55;            // stay under the 60/min hard cap
          const WINDOW_MS = 60_000;        // 1-minute sliding window
          const MAX_QUEUE = 200;           // max queued requests
          const MAX_RETRIES = 10;          // max retries on 429
          const BASE_WAIT_MS = 62_000;     // base wait on 429 (just over 1 min)
          const MAX_WAIT_MS = 180_000;     // max wait between retries (3 min)
          const UPSTREAM_TIMEOUT = 300_000; // 5 min timeout for LLM responses

          // ── State ─────────────────────────────────────
          const timestamps = [];           // sliding window of request timestamps
          let totalForwarded = 0;
          let total429Caught = 0;
          let totalRetries = 0;
          let totalStreamed = 0;
          let queueHighWater = 0;

          // ── Sliding-window rate limiter ────────────────
          function pruneWindow() {
            const cutoff = Date.now() - WINDOW_MS;
            while (timestamps.length > 0 && timestamps[0] < cutoff) {
              timestamps.shift();
            }
          }

          function recordRequest() {
            timestamps.push(Date.now());
          }

          function msUntilSlotFrees() {
            pruneWindow();
            if (timestamps.length < RPM_LIMIT) return 0;
            return Math.max(0, timestamps[0] + WINDOW_MS - Date.now() + 50);
          }

          // ── Serial queue ──────────────────────────────
          const queue = [];
          let processing = false;

          function enqueue(task) {
            if (queue.length >= MAX_QUEUE) return false;
            queue.push(task);
            if (queue.length > queueHighWater) queueHighWater = queue.length;
            drainQueue();
            return true;
          }

          async function drainQueue() {
            if (processing || queue.length === 0) return;
            processing = true;
            while (queue.length > 0) {
              const task = queue.shift();
              try { await task(); } catch (e) { log(`[ERROR] Task failed: ${e.message}`); }
            }
            processing = false;
          }

          // ── Helpers ───────────────────────────────────
          function log(msg) {
            console.log(`${new Date().toISOString()} [rate-limit-proxy] ${msg}`);
          }

          function sleep(ms) {
            return new Promise((r) => setTimeout(r, ms));
          }

          function readBody(stream) {
            return new Promise((resolve, reject) => {
              const chunks = [];
              stream.on("data", (c) => chunks.push(c));
              stream.on("end", () => resolve(Buffer.concat(chunks)));
              stream.on("error", reject);
            });
          }

          // ── Peek request: read ONLY status + headers, buffer first chunk ──
          // Returns { statusCode, headers, firstChunk, upstreamRes } so we can
          // decide whether to retry (429) or stream through. Does NOT consume
          // the full body.
          function peekUpstream(method, url, headers, body) {
            return new Promise((resolve, reject) => {
              const opts = {
                hostname: UPSTREAM_HOST,
                port: UPSTREAM_PORT,
                path: url,
                method,
                headers: { ...headers, host: `${UPSTREAM_HOST}:${UPSTREAM_PORT}` },
                timeout: UPSTREAM_TIMEOUT,
              };

              const upstream = http.request(opts, (upRes) => {
                // Pause the stream until we decide what to do
                upRes.pause();

                resolve({
                  statusCode: upRes.statusCode,
                  headers: upRes.headers,
                  upstreamRes: upRes,
                });
              });

              upstream.on("timeout", () => {
                upstream.destroy(new Error("upstream timeout"));
              });
              upstream.on("error", reject);

              if (body && body.length > 0) upstream.write(body);
              upstream.end();
            });
          }

          // ── Drain and discard an upstream response (for 429 retries) ──
          function discardResponse(upstreamRes) {
            return new Promise((resolve) => {
              upstreamRes.resume();
              upstreamRes.on("end", resolve);
              upstreamRes.on("error", resolve); // ignore errors during discard
            });
          }

          // ── Pipe upstream response to client (streaming) ──────────
          function pipeResponse(upstreamRes, res) {
            return new Promise((resolve, reject) => {
              upstreamRes.resume();
              upstreamRes.pipe(res);
              upstreamRes.on("end", resolve);
              upstreamRes.on("error", (err) => {
                res.destroy(err);
                reject(err);
              });
              res.on("close", () => {
                // Client disconnected early — destroy upstream to free resources
                if (!upstreamRes.destroyed) upstreamRes.destroy();
                resolve();
              });
            });
          }

          // ── Forward non-completions requests (buffered, simple) ───
          function forwardBuffered(method, url, headers, body) {
            return new Promise((resolve, reject) => {
              const opts = {
                hostname: UPSTREAM_HOST,
                port: UPSTREAM_PORT,
                path: url,
                method,
                headers: { ...headers, host: `${UPSTREAM_HOST}:${UPSTREAM_PORT}` },
                timeout: UPSTREAM_TIMEOUT,
              };

              const upstream = http.request(opts, (upRes) => {
                const chunks = [];
                upRes.on("data", (c) => chunks.push(c));
                upRes.on("end", () => {
                  resolve({ statusCode: upRes.statusCode, headers: upRes.headers, body: Buffer.concat(chunks) });
                });
                upRes.on("error", reject);
              });

              upstream.on("timeout", () => upstream.destroy(new Error("upstream timeout")));
              upstream.on("error", reject);

              if (body && body.length > 0) upstream.write(body);
              upstream.end();
            });
          }

          // ── Handle a single proxied completions request ───────────
          // Strategy: peek at the status code first. If 429, discard the
          // response, backoff, and retry. If 200, pipe the full response
          // (including SSE stream) directly to the client with zero buffering.
          async function handleRequest(req, res, body) {
            for (let attempt = 0; attempt <= MAX_RETRIES; attempt++) {
              // Wait for a rate-limit slot
              let waitMs = msUntilSlotFrees();
              while (waitMs > 0) {
                log(`[THROTTLE] Waiting ${(waitMs / 1000).toFixed(1)}s for rate window (attempt ${attempt + 1}/${MAX_RETRIES + 1}, queue=${queue.length})`);
                await sleep(waitMs);
                waitMs = msUntilSlotFrees();
              }

              recordRequest();
              totalForwarded++;

              try {
                const peek = await peekUpstream(req.method, req.url, req.headers, body);

                if (peek.statusCode === 429) {
                  total429Caught++;
                  // Discard the 429 response body before retrying
                  await discardResponse(peek.upstreamRes);

                  const backoff = Math.min(BASE_WAIT_MS * Math.pow(1.5, attempt), MAX_WAIT_MS);
                  const jitter = backoff * (0.9 + Math.random() * 0.2);
                  log(`[429 CAUGHT] Upstream 429 (attempt ${attempt + 1}/${MAX_RETRIES + 1}). Backoff ${(jitter / 1000).toFixed(1)}s`);
                  totalRetries++;
                  await sleep(jitter);
                  continue;
                }

                // Non-429: stream the response directly to client
                const isStream = (peek.headers["content-type"] || "").includes("text/event-stream");
                if (isStream) totalStreamed++;

                res.writeHead(peek.statusCode, peek.headers);
                await pipeResponse(peek.upstreamRes, res);
                return;

              } catch (err) {
                log(`[ERROR] Upstream failed: ${err.message} (attempt ${attempt + 1}/${MAX_RETRIES + 1})`);
                if (attempt < MAX_RETRIES) {
                  await sleep(Math.min(5000 * Math.pow(2, attempt), 60000));
                  continue;
                }
              }
            }

            // All retries exhausted
            log(`[EXHAUSTED] All ${MAX_RETRIES + 1} attempts failed for ${req.method} ${req.url}`);
            if (!res.headersSent) {
              res.writeHead(502, { "content-type": "application/json" });
              res.end(JSON.stringify({
                error: {
                  message: "Rate limit proxy: all retries exhausted. Upstream API temporarily unavailable.",
                  type: "rate_limit_proxy_exhausted",
                  code: 502,
                },
              }));
            }
          }

          // ── HTTP Server ───────────────────────────────
          const server = http.createServer(async (req, res) => {
            const body = await readBody(req);

            // Non-completions endpoints: forward immediately (buffered, no rate limiting)
            if (!req.url.includes("/chat/completions")) {
              try {
                const upRes = await forwardBuffered(req.method, req.url, req.headers, body);
                res.writeHead(upRes.statusCode, upRes.headers);
                res.end(upRes.body);
              } catch (err) {
                log(`[ERROR] Passthrough failed: ${err.message}`);
                if (!res.headersSent) {
                  res.writeHead(502, { "content-type": "application/json" });
                  res.end(JSON.stringify({ error: { message: err.message } }));
                }
              }
              return;
            }

            // Queue the completions request
            const ok = enqueue(() => handleRequest(req, res, body));
            if (!ok) {
              log(`[QUEUE FULL] Rejecting request (queue=${MAX_QUEUE})`);
              res.writeHead(503, { "content-type": "application/json" });
              res.end(JSON.stringify({
                error: {
                  message: "Rate limit proxy: queue full. Too many concurrent requests.",
                  type: "rate_limit_proxy_queue_full",
                  code: 503,
                },
              }));
            }
          });

          server.listen(LISTEN_PORT, "127.0.0.1", () => {
            log(`Listening on 127.0.0.1:${LISTEN_PORT}`);
            log(`Forwarding to ${UPSTREAM_HOST}:${UPSTREAM_PORT}`);
            log(`Rate limit: ${RPM_LIMIT} req/min (sliding window)`);
            log(`Max retries on 429: ${MAX_RETRIES}`);
            log(`Streaming: enabled (SSE pass-through)`);
          });

          // ── Periodic stats ────────────────────────────
          setInterval(() => {
            pruneWindow();
            log(`[STATS] forwarded=${totalForwarded} streamed=${totalStreamed} 429s_caught=${total429Caught} retries=${totalRetries} window=${timestamps.length}/${RPM_LIMIT} queue=${queue.length} queue_hwm=${queueHighWater}`);
          }, 120_000);

          // ── Graceful shutdown ─────────────────────────
          process.on("SIGTERM", () => { log("SIGTERM received"); server.close(() => process.exit(0)); });
          process.on("SIGINT", () => { log("SIGINT received"); server.close(() => process.exit(0)); });
          PROXY_EOF

          echo "Rate-limit proxy script created at /tmp/rate-limit-proxy.mjs"
          echo "::endgroup::"

      - name: Start rate-limit proxy
        run: |
          set -euo pipefail
          echo "::group::Starting rate-limit proxy"

          nohup node /tmp/rate-limit-proxy.mjs > /tmp/rate-limit-proxy.log 2>&1 &
          RATE_PROXY_PID=$!
          echo "Rate-limit proxy started (PID: $RATE_PROXY_PID)"
          echo "RATE_PROXY_PID=$RATE_PROXY_PID" >> "$GITHUB_ENV"

          # Wait for the proxy to be ready
          echo "Waiting for rate-limit proxy to be ready..."
          READY=false
          for i in $(seq 1 30); do
            if ! kill -0 $RATE_PROXY_PID 2>/dev/null; then
              echo "::error::Rate-limit proxy died unexpectedly"
              cat /tmp/rate-limit-proxy.log || true
              exit 1
            fi

            # Use head -c3 to ensure we only get the 3-digit HTTP code
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
              -H "Authorization: Bearer dummykey" \
              http://127.0.0.1:8318/v1/models 2>/dev/null | head -c3 || echo "000")

            if [ "$HTTP_CODE" = "200" ]; then
              echo "Rate-limit proxy is ready! (HTTP $HTTP_CODE) — proxying 8318 -> 8317"
              READY=true
              break
            fi

            echo "  Attempt $i/30: HTTP $HTTP_CODE - waiting..."
            sleep 1
          done

          if [ "$READY" = "false" ]; then
            echo "::error::Rate-limit proxy didn't become ready within 30 seconds"
            cat /tmp/rate-limit-proxy.log || true
            exit 1
          fi

          # Show models through the proxy
          echo ""
          echo "Models available through rate-limit proxy:"
          curl -s -H "Authorization: Bearer dummykey" \
            http://127.0.0.1:8318/v1/models 2>/dev/null | jq '.data[].id' 2>/dev/null || echo "(could not list models)"

          echo ""
          echo "Rate-limit proxy logs:"
          cat /tmp/rate-limit-proxy.log || true

          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 5. Run OpenClaw non-interactive onboarding
      #    NOTE: Points to port 8318 (rate-limit proxy)
      #    instead of 8317 (CLIProxyAPI direct)
      # ──────────────────────────────────────────────

      - name: Run OpenClaw onboarding (non-interactive)
        run: |
          set -euo pipefail
          echo "::group::Running OpenClaw onboarding"

          echo "Onboarding with model: $MODEL_ID"
          echo "Using rate-limit proxy at http://127.0.0.1:8318/v1"

          openclaw onboard --non-interactive --accept-risk \
            --flow quickstart \
            --auth-choice custom-api-key \
            --custom-base-url "http://127.0.0.1:8318/v1" \
            --custom-api-key "dummykey" \
            --custom-model-id "$MODEL_ID" \
            --custom-compatibility openai \
            --skip-channels \
            --skip-skills \
            --skip-health \
            --skip-ui

          echo "Non-interactive onboarding completed"
          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 5.5. CRITICAL FIX: Patch contextWindow and maxTokens
      #      OpenClaw defaults custom models to contextWindow: 4096
      #      but requires minimum 16000 tokens. This patch fixes the
      #      "Model context window too small (4096 tokens)" error.
      # ──────────────────────────────────────────────

      - name: Fix model context window (patch contextWindow and maxTokens)
        run: |
          set -euo pipefail
          echo "::group::Fixing model context window"

          CONFIG_FILE="$HOME/.openclaw/openclaw.json"

          if [ ! -f "$CONFIG_FILE" ]; then
            echo "::error::OpenClaw config file not found at $CONFIG_FILE"
            exit 1
          fi

          echo "Before fix - model config:"
          jq '.models.providers' "$CONFIG_FILE" 2>/dev/null || echo "(could not read models)"

          # Patch ALL models in ALL providers to have correct contextWindow and maxTokens.
          # This fixes the "Model context window too small (4096 tokens). Minimum is 16000." error.
          # The contextWindow default for custom-api-key models is 4096 which is too small.
          jq --argjson ctx "$CONTEXT_WINDOW" --argjson maxTok "$MAX_TOKENS" '
            if .models.providers then
              .models.providers |= with_entries(
                .value.models = [
                  .value.models[] |
                  .contextWindow = $ctx |
                  .maxTokens = $maxTok
                ]
              )
            else . end
          ' "$CONFIG_FILE" > "${CONFIG_FILE}.tmp" && mv "${CONFIG_FILE}.tmp" "$CONFIG_FILE"

          echo ""
          echo "After fix - model config:"
          jq '.models.providers' "$CONFIG_FILE"

          # Verify the fix worked
          ACTUAL_CTX=$(jq -r '[.models.providers[].models[].contextWindow] | first' "$CONFIG_FILE" 2>/dev/null || echo "0")
          echo ""
          echo "Verified contextWindow: $ACTUAL_CTX (required minimum: 16000)"

          if [ "$ACTUAL_CTX" -lt 16000 ]; then
            echo "::error::contextWindow is still below 16000 after patching!"
            exit 1
          fi

          echo "Context window fix applied successfully!"
          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 6. Patch config for Discord, Skills, Hooks
      # ──────────────────────────────────────────────

      - name: Patch OpenClaw config for Discord
        env:
          DISCORD_BOT_TOKEN: ${{ github.event.inputs.discord_bot_token }}
        run: |
          set -euo pipefail
          echo "::group::Patching OpenClaw config for Discord"

          CONFIG_FILE="$HOME/.openclaw/openclaw.json"

          if [ ! -f "$CONFIG_FILE" ]; then
            echo "::error::OpenClaw config file not found at $CONFIG_FILE"
            echo "Non-interactive onboarding may have failed."
            exit 1
          fi

          # Patch Discord configuration
          jq --arg token "$DISCORD_BOT_TOKEN" '
            .channels = (.channels // {}) |
            .channels.discord = {
              "enabled": true,
              "token": $token,
              "groupPolicy": "open",
              "guilds": {}
            }
          ' "$CONFIG_FILE" > "${CONFIG_FILE}.tmp" && mv "${CONFIG_FILE}.tmp" "$CONFIG_FILE"

          echo "Discord configuration patched successfully"
          echo "::endgroup::"

      - name: Patch OpenClaw config for Skills and Hooks
        run: |
          set -euo pipefail
          echo "::group::Patching Skills and Hooks"

          CONFIG_FILE="$HOME/.openclaw/openclaw.json"

          # Patch skills + hooks in one go
          jq '
            .skills = (.skills // {}) |
            .skills.install = { "nodeManager": "npm" } |
            .skills.entries = (.skills.entries // {}) |
            .hooks = (.hooks // {}) |
            .hooks.internal = { "enabled": false, "entries": {} }
          ' "$CONFIG_FILE" > "${CONFIG_FILE}.tmp" && mv "${CONFIG_FILE}.tmp" "$CONFIG_FILE"

          echo "Skills and Hooks configuration patched"
          echo "::endgroup::"

      - name: Install clawhub skill
        run: |
          set -euo pipefail
          echo "::group::Installing clawhub skill"

          mkdir -p "$HOME/.openclaw/workspace"

          CONFIG_FILE="$HOME/.openclaw/openclaw.json"

          # Register the clawhub skill in the config.
          # The OpenClaw config schema for skills.entries is strict — only
          # these keys are allowed: enabled, apiKey, env, config.
          # Any other key (e.g. "source") causes a validation error and
          # crashes the gateway with "Unrecognized key".
          # clawhub is a bundled/workspace skill that OpenClaw discovers
          # automatically once enabled here.
          jq '
            .skills.entries["@openclaw/clawhub"] = {
              "enabled": true
            }
          ' "$CONFIG_FILE" > "${CONFIG_FILE}.tmp" 2>/dev/null && mv "${CONFIG_FILE}.tmp" "$CONFIG_FILE" && echo "clawhub skill enabled in config" || {
            echo "::warning::Could not add clawhub skill - continuing without it"
          }

          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 7. Verify final configuration
      # ──────────────────────────────────────────────

      - name: Verify final configuration
        run: |
          set -euo pipefail
          echo "::group::Final configuration"

          CONFIG_FILE="$HOME/.openclaw/openclaw.json"

          echo "=== Final OpenClaw Config (redacted) ==="
          jq '
            if .channels?.discord?.token then
              .channels.discord.token = "***REDACTED***"
            else . end |
            if .models?.providers then
              .models.providers |= with_entries(
                if .value.apiKey then
                  .value.apiKey = "***REDACTED***"
                else . end
              )
            else . end |
            if .gateway?.auth?.token then
              .gateway.auth.token = "***REDACTED***"
            else . end
          ' "$CONFIG_FILE"

          # Validate that skill entries don't contain unrecognized keys.
          # The OpenClaw schema only allows: enabled, apiKey, env, config.
          # Any other key will cause the gateway to crash.
          echo ""
          echo "=== Config Schema Pre-Check ==="
          INVALID_KEYS=$(jq -r '
            .skills.entries // {} | to_entries[] |
            .key as $skill |
            .value | keys[] |
            select(. != "enabled" and . != "apiKey" and . != "env" and . != "config") |
            "\($skill): unrecognized key \"\(.)\""
          ' "$CONFIG_FILE" 2>/dev/null || true)

          if [ -n "$INVALID_KEYS" ]; then
            echo "::error::Config has invalid skill entry keys that will crash the gateway!"
            echo "$INVALID_KEYS"
            echo ""
            echo "Attempting auto-fix: stripping unrecognized keys..."
            jq '
              .skills.entries //= {} |
              .skills.entries |= with_entries(
                .value |= with_entries(
                  select(.key == "enabled" or .key == "apiKey" or .key == "env" or .key == "config")
                )
              )
            ' "$CONFIG_FILE" > "${CONFIG_FILE}.tmp" && mv "${CONFIG_FILE}.tmp" "$CONFIG_FILE"
            echo "Auto-fix applied. Cleaned config skill entries:"
            jq '.skills.entries' "$CONFIG_FILE"
          else
            echo "Skill entries schema OK (no unrecognized keys)"
          fi

          echo ""
          echo "=== CLIProxyAPI Status ==="
          if kill -0 $PROXY_PID 2>/dev/null; then
            echo "CLIProxyAPI is running (PID: $PROXY_PID)"
            QWEN_COUNT=$(find "$AUTH_DIR" -maxdepth 1 -name 'qwen-*.json' 2>/dev/null | wc -l)
            GEMINI_COUNT=$(find "$AUTH_DIR" -maxdepth 1 -name 'gemini-cli-*.json' 2>/dev/null | wc -l)
            echo "Qwen tokens loaded: $QWEN_COUNT"
            echo "Gemini CLI tokens loaded: $GEMINI_COUNT"
          else
            echo "::error::CLIProxyAPI is NOT running!"
            cat /tmp/cliproxyapi.log || true
            exit 1
          fi

          echo ""
          echo "=== Rate-Limit Proxy Status ==="
          if kill -0 $RATE_PROXY_PID 2>/dev/null; then
            echo "Rate-limit proxy is running (PID: $RATE_PROXY_PID)"
            echo "Proxying: 127.0.0.1:8318 -> 127.0.0.1:8317"
          else
            echo "::error::Rate-limit proxy is NOT running!"
            cat /tmp/rate-limit-proxy.log || true
            exit 1
          fi

          echo ""
          echo "=== Configuration Summary ==="
          echo "LLM Provider: Custom (Rate-Limit Proxy -> CLIProxyAPI -> $PROVIDER)"
          echo "Model: $MODEL_ID"
          echo "Context Window: $CONTEXT_WINDOW"
          echo "Max Tokens: $MAX_TOKENS"
          echo "API Base: http://127.0.0.1:8318/v1 (rate-limited proxy)"
          echo "Upstream: http://127.0.0.1:8317/v1 (CLIProxyAPI)"
          echo "Rate Limit: 55 req/min (Qwen hard limit: 60/min)"
          echo "Channel: Discord (Open access)"

          echo "::endgroup::"

      - name: Show summary
        run: |
          cat << EOF >> $GITHUB_STEP_SUMMARY
          ## OpenClaw Running

          ### Configuration
          | Setting | Value |
          |---------|-------|
          | LLM Provider | Custom (Rate-Limit Proxy -> CLIProxyAPI -> $PROVIDER) |
          | Model | \`$MODEL_ID\` |
          | Context Window | $CONTEXT_WINDOW tokens |
          | Max Tokens | $MAX_TOKENS tokens |
          | API Endpoint | \`http://127.0.0.1:8318/v1\` (rate-limited) |
          | Upstream | \`http://127.0.0.1:8317/v1\` (CLIProxyAPI) |
          | Rate Limit | 55 req/min with auto-retry on 429 |
          | Routing | Round-robin across all $PROVIDER tokens |
          | Channel | Discord (Open access - all channels) |
          | Gateway | Local (port 18789, loopback, token auth) |
          | Timeout | 6 hours |

          ### Rate Limit Protection
          A Node.js rate-limit proxy sits between OpenClaw and CLIProxyAPI:
          - **Streaming**: SSE/streaming responses are piped directly through with zero buffering
          - **Sliding window**: Tracks requests per minute, throttles at 55/min (below Qwen's 60/min hard cap)
          - **Auto-retry on 429**: If upstream returns 429, proxy waits 62s+ with exponential backoff and retries
          - **Transparent to OpenClaw**: OpenClaw never sees rate limit errors — requests are simply delayed
          - **Serial queue**: Ensures no request storms overwhelm the API
          - **Up to 10 retries**: With escalating backoff up to 3 minutes between attempts

          ### Context Window Fix
          The workflow patches the model's \`contextWindow\` from the default 4096 to $CONTEXT_WINDOW tokens.
          This fixes the "Model context window too small (4096 tokens). Minimum is 16000." error.

          ### Status
          The OpenClaw gateway is running with Discord connected.
          The bot should be online and responding to messages.
          The workflow will keep running for up to 6 hours or until manually cancelled.
          EOF

      # ──────────────────────────────────────────────
      # 7.5. Run doctor --fix to clean up any config issues
      # ──────────────────────────────────────────────

      - name: Run OpenClaw doctor --fix
        run: |
          set -euo pipefail
          echo "::group::Running openclaw doctor --fix"

          # doctor --fix removes unrecognized keys and applies
          # recommended changes (e.g. enabling Discord when token
          # is present). This is a safety net in case any config
          # patching introduced unknown fields.
          if openclaw doctor --fix 2>&1; then
            echo "Doctor completed successfully"
          else
            echo "::warning::Doctor exited with non-zero status — continuing anyway"
          fi

          echo ""
          echo "Config after doctor --fix:"
          jq '.' "$HOME/.openclaw/openclaw.json" 2>/dev/null | head -80 || true

          echo "::endgroup::"

      # ──────────────────────────────────────────────
      # 8. Start OpenClaw gateway and keep alive
      # ──────────────────────────────────────────────

      - name: Start OpenClaw gateway and run indefinitely
        env:
          DISCORD_BOT_TOKEN: ${{ github.event.inputs.discord_bot_token }}
        run: |
          set -euo pipefail

          echo "============================================"
          echo "  Starting OpenClaw Gateway + Discord Bot"
          echo "  Provider: $PROVIDER | Model: $MODEL_ID"
          echo "  Context Window: $CONTEXT_WINDOW tokens"
          echo "  Rate Limit Proxy: 127.0.0.1:8318 -> 8317"
          echo "============================================"
          echo ""

          # Verify CLIProxyAPI is still running
          if ! kill -0 $PROXY_PID 2>/dev/null; then
            echo "::error::CLIProxyAPI died before gateway start!"
            cat /tmp/cliproxyapi.log || true
            exit 1
          fi
          echo "CLIProxyAPI is alive (PID: $PROXY_PID)"

          # Verify rate-limit proxy is still running
          if ! kill -0 $RATE_PROXY_PID 2>/dev/null; then
            echo "::error::Rate-limit proxy died before gateway start!"
            cat /tmp/rate-limit-proxy.log || true
            exit 1
          fi
          echo "Rate-limit proxy is alive (PID: $RATE_PROXY_PID)"

          # Start the OpenClaw gateway directly (systemd doesn't work well in GitHub Actions)
          # The gateway connects to Discord, handles messages, and proxies to CLIProxyAPI
          echo "Starting OpenClaw gateway..."
          nohup openclaw gateway > /tmp/openclaw-gateway.log 2>&1 &
          GATEWAY_PID=$!
          echo "Gateway started (PID: $GATEWAY_PID)"

          # Give the gateway time to initialize and connect to Discord
          echo "Waiting for gateway to initialize..."
          sleep 15

          # Check if gateway is still running
          if ! kill -0 $GATEWAY_PID 2>/dev/null; then
            echo "::error::Gateway process died during startup!"
            echo "=== Gateway logs ==="
            cat /tmp/openclaw-gateway.log || true
            echo "=== CLIProxyAPI logs ==="
            cat /tmp/cliproxyapi.log || true
            echo "=== Rate-limit proxy logs ==="
            cat /tmp/rate-limit-proxy.log || true
            exit 1
          fi

          echo ""
          echo "Gateway is running!"
          echo ""

          # Show initial gateway logs
          echo "=== Initial Gateway Logs ==="
          cat /tmp/openclaw-gateway.log || true
          echo "=== End Initial Logs ==="
          echo ""

          # Check gateway health
          openclaw health --timeout 10000 2>/dev/null && echo "Health check: PASSED" || echo "Health check: gateway may still be initializing"

          echo ""
          echo "============================================"
          echo "  OpenClaw is LIVE! Discord bot is online."
          echo "  Rate limit proxy active (55 req/min cap)."
          echo "  The workflow will keep running for ~6 hours."
          echo "  Cancel this workflow to stop the bot."
          echo "============================================"
          echo ""

          # Keep-alive loop: monitor processes and print status every 5 minutes
          ITERATION=0
          while true; do
            ITERATION=$((ITERATION + 1))

            # Check if CLIProxyAPI is alive
            if ! kill -0 $PROXY_PID 2>/dev/null; then
              echo ""
              echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') [ERROR] CLIProxyAPI (PID: $PROXY_PID) died!"
              echo "=== CLIProxyAPI logs ==="
              tail -50 /tmp/cliproxyapi.log || true

              # Try to restart CLIProxyAPI
              echo "Attempting to restart CLIProxyAPI..."
              nohup cliproxyapi -config "$AUTH_DIR/config.yaml" >> /tmp/cliproxyapi.log 2>&1 &
              PROXY_PID=$!
              echo "CLIProxyAPI restarted (PID: $PROXY_PID)"
              sleep 5
            fi

            # Check if rate-limit proxy is alive
            if ! kill -0 $RATE_PROXY_PID 2>/dev/null; then
              echo ""
              echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') [ERROR] Rate-limit proxy (PID: $RATE_PROXY_PID) died!"
              echo "=== Rate-limit proxy logs ==="
              tail -50 /tmp/rate-limit-proxy.log || true

              # Try to restart rate-limit proxy
              echo "Attempting to restart rate-limit proxy..."
              nohup node /tmp/rate-limit-proxy.mjs >> /tmp/rate-limit-proxy.log 2>&1 &
              RATE_PROXY_PID=$!
              echo "Rate-limit proxy restarted (PID: $RATE_PROXY_PID)"
              sleep 3
            fi

            # Check if gateway is alive
            if ! kill -0 $GATEWAY_PID 2>/dev/null; then
              echo ""
              echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') [ERROR] Gateway (PID: $GATEWAY_PID) died!"
              echo "=== Gateway logs ==="
              tail -50 /tmp/openclaw-gateway.log || true

              # Try to restart gateway
              echo "Attempting to restart gateway..."
              nohup openclaw gateway >> /tmp/openclaw-gateway.log 2>&1 &
              GATEWAY_PID=$!
              echo "Gateway restarted (PID: $GATEWAY_PID)"
              sleep 10
            fi

            # Print status every 5 minutes (every 10 iterations of 30s sleep)
            if [ $((ITERATION % 10)) -eq 0 ]; then
              UPTIME_MIN=$((ITERATION * 30 / 60))
              echo ""
              echo "$(date -u '+%Y-%m-%d %H:%M:%S UTC') [STATUS] Uptime: ~${UPTIME_MIN}m | CLIProxyAPI PID: $PROXY_PID | Rate-Limit Proxy PID: $RATE_PROXY_PID | Gateway PID: $GATEWAY_PID"

              # Print last few lines of logs
              echo "--- Recent gateway logs ---"
              tail -5 /tmp/openclaw-gateway.log 2>/dev/null || true
              echo "--- Recent CLIProxyAPI logs ---"
              tail -5 /tmp/cliproxyapi.log 2>/dev/null || true
              echo "--- Recent rate-limit proxy logs ---"
              tail -5 /tmp/rate-limit-proxy.log 2>/dev/null || true
              echo "---"
            fi

            sleep 30
          done
